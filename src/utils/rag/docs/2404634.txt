Title: ğŸ‘¾æ‰“å¼€ RAG å¯¹æ¥å¤§æ¨¡å‹çš„é»‘ç›’ â€”â€” 9  å¤§éšè—é—®é¢˜-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘

URL Source: https://cloud.tencent.com/developer/article/2404634

Markdown Content:
å‰ä¸€æ®µæ—¶é—´ï¼Œå„ä¸ªå¤§æ¨¡å‹åœ¨äº‰æ–—ï¼šè°èƒ½æºå¸¦æ›´é•¿ã€æ›´å¤§çš„ä¸Šä¸‹æ–‡ Promptï¼Œæ¯”å¦‚ Kimi è¯´ 200 ä¸‡å­—ï¼Œé˜¿é‡Œé€šä¹‰åƒé—®åˆè¯´è‡ªå·±èƒ½è¾¾ 1000 ä¸‡å­—ï¼›å¤§å®¶éƒ½çŸ¥é“ Prompt å¾ˆé‡è¦ï¼Œä½†æ˜¯ RAG å’Œ é•¿çš„ä¸Šä¸‹æ–‡æ–‡æœ¬æºå¸¦ æ˜¯ä¸¤ä¸ªä¸åŒçš„æŠ€æœ¯æ–¹å‘ã€‚

### RAG

å…ˆæ¥ç®€å•ä»‹ç»ä¸€ä¸‹ä»€ä¹ˆæ˜¯ RAG ï¼ˆå¢å¼ºæœç´¢ç”Ÿæˆï¼‰ï¼Œå¾ˆç®€å•ï¼š

å½“æˆ‘ä»¬é—® ChatGPT ä¸€ä¸ªæ¯”è¾ƒä¸“ä¸šçš„é—®é¢˜æ—¶ï¼Œä»–å°±æ˜¯å¼€å§‹å›ç­”è½±è¾˜è¯äº†ï¼Œé€šç”¨å¤§æ¨¡å‹åœ¨ä¸“ä¸šé¢†åŸŸçš„åº”ç­”èƒ½åŠ›æœ‰é™ï¼›

æ‰€æœ‰è¿™ä¸ªæ—¶å€™ï¼Œæˆ‘ä»¬é€šè¿‡ä¸°å¯Œ Prompt ç»™ä»–ä»‹ç»ä¸€ä¸‹ç›¸å…³èƒŒæ™¯ï¼Œç„¶åå¤§æ¨¡å‹å°±æœ‰æ›´ä¸“ä¸šçš„åº”ç­”èƒ½åŠ›äº†ã€‚

è¿™ä¸ªä¸°å¯Œ Prompt çš„è¿‡ç¨‹å°±æ˜¯ RAG â€”â€” å¢å¼ºæœç´¢ç”Ÿæˆã€‚

å®é™…æ“ä½œä¼šæ›´å¤æ‚ä¸€ç‚¹ï¼Œä½†æ˜¯åŸç†å°±æ˜¯è¿™ä¹ˆä¸€ä¸ªåŸç†ï¼Œå¦‚å›¾ï¼š

![Image 23](https://developer.qcloudimg.com/http-save/yehe-7738744/878677f2afa0832538b7a180b662d637.webp)

å¦‚ä¸Šå›¾ï¼Œå½“æˆ‘ä»¬é—®å¤§æ¨¡å‹ï¼šâ€œäº”å››è¿åŠ¨çš„å†å²æ„ä¹‰â€ï¼Œå®ƒå¯èƒ½æ³›æ³›è€Œè°ˆï¼›æ­¤æ—¶ï¼Œæ­¤æ—¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸“ä¸šçŸ¥è¯†åº“ï¼ˆä¹¦ã€æ•™æã€è®ºæ–‡æ–‡çŒ®ç­‰ï¼‰ï¼Œç„¶åé€šè¿‡æå–æ–‡æœ¬å½¢æˆåŒºå—ï¼Œå½¢æˆå‘é‡åº“ï¼›å½“æˆ‘ä»¬å†æ¬¡æé—®çš„æ—¶å€™ï¼Œä¼šç»“åˆå‘é‡åº“å½¢æˆä¸€ä¸ªæ›´åŠ å®Œå¤‡çš„Prompt ï¼Œæ­¤æ—¶ï¼Œå¤§æ¨¡å‹å°±èƒ½å¾ˆå¥½åœ°å›ç­”æˆ‘ä»¬çš„ä¸“ä¸šé—®é¢˜äº†ï¼

è¨€è€Œæ€»ä¹‹ï¼Œå¤§æ•°æ®æ—¶ä»£ï¼Œå¾ˆå¤šå…¬å¸éƒ½æ‹¥æœ‰å¤§é‡çš„ä¸“æœ‰æ•°æ®ï¼Œå¦‚æœèƒ½åŸºäºå®ƒä»¬åˆ›å»º RAGï¼Œå°†æ˜¾è‘—æå‡å¤§æ¨¡å‹çš„ç‰¹å¼‚æ€§ã€‚

### æ„å»º RAG

æœ¬ç¯‡ä¸æ˜¯æƒ³è®² RAG æ¦‚å¿µï¼Œè€Œæ˜¯æƒ³å†æ·±å…¥æ¢ç´¢ä¸€ä¸‹ï¼šRAG çš„æ„å»ºï¼›

é€šå¸¸æ¥è¯´ï¼Œæ„å»º RAG çš„è¿‡ç¨‹æœ‰ï¼š

*   å°†æ–‡æ¡£åˆ†å‰²æˆå‡åŒ€çš„å—ï¼Œæ¯ä¸ªå—éƒ½æ˜¯ä¸€æ®µåŸå§‹æ–‡æœ¬ï¼›
*   ä¸ºæ¯ä¸ªå—ç”ŸæˆåµŒå…¥ï¼ˆä¾‹å¦‚ OpenAl åµŒå…¥ï¼Œsentence_transformerï¼‰ï¼›
*   å°†æ¯ä¸ªå—å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­ï¼›
*   ä»å‘é‡æ•°æ®åº“é›†åˆä¸­æ‰¾åˆ°æœ€ç›¸ä¼¼çš„Top-kå—ï¼›
*   æ¥å…¥LLMå“åº”åˆæˆæ¨¡å—ï¼›

![Image 24](https://developer.qcloudimg.com/http-save/yehe-7738744/d7bd927811691d45a8f95ba46c96cb52.webp)

![Image 25](https://developer.qcloudimg.com/http-save/yehe-7738744/b2ed2a65fdcbef0ba7c051999d8bf9f5.webp)

ç®€æ˜“ RAGï¼š

```
!pip install llama-index

# My OpenAI Key
import os
os.environ['OPENAI_API_KEY'] = ""


import logging
import sys
import requests

logging.basicConfig(stream=sys.stdout, level=logging.INFO)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))

from llama_index import VectorStoreIndex, SimpleDirectoryReader
from IPython.display import Markdown, display

# download paul graham's essay
response = requests.get("https://www.dropbox.com/s/f6bmb19xdg0xedm/paul_graham_essay.txt?dl=1")
essay_txt = response.text
with open("pg_essay.txt", "w") as fp:
  fp.write(essay_txt)
  
  
  # load documents
documents = SimpleDirectoryReader(input_files=['pg_essay.txt']).load_data()


index = VectorStoreIndex.from_documents(documents)


# set Logging to DEBUG for more detailed outputs
query_engine = index.as_query_engine(similarity_top_k=2)

response = query_engine.query(
    "What did the author do growing up?",
)


print(response.source_nodes[0].node.get_text())
```

ä»¥ä¸Šä»£ç æ˜¯ä¸€ä¸ªç®€å•çš„ RAG ç®¡é“ï¼Œæ¼”ç¤ºäº†åŠ è½½ä¸€ç¯‡ä¸“ä¸šæ–‡ç« ï¼Œå¯¹å…¶è¿›è¡Œåˆ†å—ï¼Œå¹¶ä½¿ç”¨ llama-index åº“åˆ›å»º RAG ç®¡é“ã€‚è¿™ç§ç®€æ˜“çš„ RAG é€‚åˆä¸€äº›å°è€Œç¾çš„ä¸“ä¸šé—®é¢˜ã€‚

ç°å®ä¸–ç•Œä¸­ï¼Œä¸“ä¸šé—®é¢˜å¾€å¾€ä¼šæ›´åŠ å¤æ‚ã€‚

å¯¹äºå¾ˆå¤šäººæ¥è¯´ï¼ŒRAG çš„å¼•å…¥ã€ä¸å¤§æ¨¡å‹çš„å¯¹æ¥æ˜¯ä¸€ä¸ªé»‘ç›’ï¼Œä»»ä½•å¾®å°å‚æ•°çš„å˜åŠ¨éƒ½å°†å¼•èµ·ç»“æœå‘ç”Ÿå¾ˆå¤§çš„å˜åŒ–ã€‚

![Image 26: image.png](https://developer.qcloudimg.com/http-save/yehe-7738744/24f10e69c34a2503ebba73edbaffaa33.webp)

image.png

å¹¿æ³›ç†è§£ï¼Œåœ¨æ£€ç´¢ä¸­ï¼Œå®¹æ˜“é€ æˆçš„é—®é¢˜æœ‰ï¼š

*   ä½ç²¾åº¦ï¼šæ£€ç´¢é›†åˆä¸­å¹¶éæ‰€æœ‰ç‰‡æ®µéƒ½ç›¸å…³â€”â€” å­˜åœ¨å¹»è§‰é—®é¢˜å’Œä¸­é—´ä¸¢å¤±é—®é¢˜
*   ä½å¬å›ç‡ï¼šå¹¶éæ‰€æœ‰ç›¸å…³ç‰‡æ®µéƒ½è¢«æ£€ç´¢åˆ°â€”â€”ç¼ºä¹è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡è®©LLMåˆæˆç­”æ¡ˆï¼ˆè¿™ä¹Ÿå°è¯äº†æ‰©å¼ ä¸Šä¸‹æ–‡å®¹é‡çš„å¿…è¦æ€§ï¼‰
*   ä¿¡æ¯è¿‡æ—¶ï¼šæ•°æ®å†—ä½™æˆ–å·²è¿‡æ—¶

è¿™æ ·ä¼šå¯¼è‡´ï¼šæ¨¡å‹ç¼–é€ ä¸ç¬¦åˆä¸Šä¸‹æ–‡è¯­ä¹‰çš„ç­”æ¡ˆ/æ¨¡å‹æ²¡æœ‰å›ç­”é—®é¢˜/æ¨¡å‹ç¼–é€ æœ‰å®³çš„æˆ–å¸¦æœ‰åè§çš„ç­”æ¡ˆ

æ¥ä¸‹æ¥ï¼Œä¸€èµ·æ­ç§˜ï¼šRAG å¯¹æ¥å¤§æ¨¡å‹çš„é»‘ç›’ â€”â€” 9 å¤§é—®é¢˜

![Image 27](https://developer.qcloudimg.com/http-save/yehe-7738744/9697e3d8d827c1ad0a647d173edc6269.webp)

æ¥æºï¼š[Seven Failure Points When Engineering a Retrieval Augmented Generation System](https://cloud.tencent.com/developer/tools/blog-entry?target=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3Dhttps%253A%252F%252Farxiv.org%252Fpdf%252F2401.05856.pdf&objectId=2404634&objectType=1&isNewArticle=undefined)

#### 1. æºæ•°æ®æœ¬èº«ç¼ºå°‘ä¸Šä¸‹æ–‡

è¿™ä¸ªå¾ˆå¥½ç†è§£ï¼Œ ä½ æƒ³è¦é—®ä¸“ä¸šçš„å†å²é—®é¢˜ï¼Œå°±éœ€è¦å»ºç«‹å†å²çŸ¥è¯†åº“ï¼Œè€Œä¸æ˜¯å¯¹æ¥ä¸€ä¸ªç”Ÿç‰©æ•°æ®åº“ï¼›

å¦‚æœæºæ•°æ®è´¨é‡è¾ƒå·®ï¼Œä¾‹å¦‚åŒ…å«å†²çªä¿¡æ¯ï¼Œæ— è®ºæˆ‘ä»¬å¦‚ä½•æ„å»º RAG ç®¡é“ï¼Œæœ€ç»ˆä¹Ÿæ— æ³•ä»æä¾›çš„åƒåœ¾ä¸­ç”Ÿæˆé»„é‡‘ã€‚

æœ‰ä¸€äº›å¸¸è§çš„ç­–ç•¥å¯ä»¥æ¸…ç†æ•°æ®ï¼Œä¸¾å‡ ä¸ªä¾‹å­ï¼š

*   å»é™¤å™ªå£°å’Œä¸ç›¸å…³ä¿¡æ¯ï¼šåŒ…æ‹¬å»é™¤ç‰¹æ®Šå­—ç¬¦ã€åœé¡¿è¯ï¼ˆåƒâ€œtheâ€å’Œâ€œaâ€è¿™æ ·çš„å¸¸ç”¨è¯ï¼‰å’ŒHTMLæ ‡ç­¾ã€‚
*   è¯†åˆ«å¹¶çº æ­£é”™è¯¯ï¼šåŒ…æ‹¬æ‹¼å†™é”™è¯¯ã€æ‰“å­—é”™è¯¯å’Œè¯­æ³•é”™è¯¯ï¼›æ‹¼å†™æ£€æŸ¥å™¨å’Œè¯­è¨€æ¨¡å‹ä¹‹ç±»çš„å·¥å…·å¯ä»¥å¸®åŠ©è§£å†³è¿™äº›é—®é¢˜ã€‚
*   å»é‡ï¼šç§»é™¤é‡å¤è®°å½•æˆ–åœ¨åç½®æ£€ç´¢è¿‡ç¨‹çš„ç›¸ä¼¼è®°å½•ã€‚

è¿™é‡Œæ¨èï¼š[Unstructured.io](https://cloud.tencent.com/developer/tools/blog-entry?target=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3DUnstructured.io&objectId=2404634&objectType=1&isNewArticle=undefined) æ˜¯ä¸€å¥—æ ¸å¿ƒåº“ï¼Œèƒ½å¸®åŠ©è§£å†³æ•°æ¸…ç†ï¼Œå€¼å¾—ä¸€è¯•ã€‚

![Image 28](https://developer.qcloudimg.com/http-save/yehe-7738744/3f5213f27c25090a0959f4d5f2738ea1.webp)

è¿˜æœ‰ä¸€ä¸ªæç¤ºçš„å°æŠ€å·§ï¼šç›´æ¥å‘Šè¯‰å¤§æ¨¡å‹ï¼Œâ€œå¦‚æœä½ é‡åˆ°äº†ä½ ä¸æ‡‚çš„çŸ¥è¯†ç‚¹ï¼Œè¯·ç›´æ¥å‘Šè¯‰æˆ‘ï¼šä¸çŸ¥é“â€ï¼›

æˆ–è€…ä½ è¿˜å¯ä»¥åœ¨æ¯ä¸ª chunk é‡Œé¢æ·»åŠ ä¸Šä¸‹æ–‡ï¼›

#### 2. å…³é”®ä¿¡æ¯å‡ºç°æƒé‡è¾ƒä½

ç†è®ºä¸Šæ¥è®²ï¼Œé‡è¦çš„ä¿¡æ¯éƒ½è¦å‡ºç°åœ¨æç¤ºè¯­çš„å¤´éƒ¨ï¼Œå¦‚æœå…¶è¢«å¿½è§†ï¼Œå°†å¯¼è‡´å¤§æ¨¡å‹æ— æ³•å‡†ç¡®å“åº”ã€‚

æ‰€ä»¥ï¼ŒRAG åº”è¯¥ç»™å…³é”®ä¿¡æ¯ä»¥è¶³å¤Ÿé«˜çš„æƒé‡è®¾ç½®ï¼Œä¸€èˆ¬æœ‰ä¸¤ç§è§£å†³æ–¹æ¡ˆï¼š

*   è°ƒæ•´å—-chunk_size çš„å¤§å°
*   è°ƒæ•´ç›¸ä¼¼åº¦ top-kï¼ˆsimilarity_top_kï¼‰å‚æ•°

å¯¹æ£€ç´¢è¿‡ç¨‹ä¸­çš„æ•ˆç‡å’Œæœ‰æ•ˆæ€§è¿›è¡Œè®¾ç½®ï¼Œä»£ç ç¤ºä¾‹å¦‚ä¸‹ï¼š

```
# contains the parameters that need to be tuned
param_dict = {"chunk_size": [256, 512, 1024], "top_k": [1, 2, 5]}

# contains parameters remaining fixed across all runs of the tuning process
fixed_param_dict = {
    "docs": documents,
    "eval_qs": eval_qs,
    "ref_response_strs": ref_response_strs,
}

def objective_function_semantic_similarity(params_dict):
    chunk_size = params_dict["chunk_size"]
    docs = params_dict["docs"]
    top_k = params_dict["top_k"]
    eval_qs = params_dict["eval_qs"]
    ref_response_strs = params_dict["ref_response_strs"]

    # build index
    index = _build_index(chunk_size, docs)

    # query engine
    query_engine = index.as_query_engine(similarity_top_k=top_k)

    # get predicted responses
    pred_response_objs = get_responses(
        eval_qs, query_engine, show_progress=True
    )

    # run evaluator
    eval_batch_runner = _get_eval_batch_runner_semantic_similarity()
    eval_results = eval_batch_runner.evaluate_responses(
        eval_qs, responses=pred_response_objs, reference=ref_response_strs
    )

    # get semantic similarity metric
    mean_score = np.array(
        [r.score for r in eval_results["semantic_similarity"]]
    ).mean()

    return RunResult(score=mean_score, params=params_dict)


param_tuner = ParamTuner(
    param_fn=objective_function_semantic_similarity,
    param_dict=param_dict,
    fixed_param_dict=fixed_param_dict,
    show_progress=True,
)

results = param_tuner.tune()
```

#### 3. é‡æ’åºåç¼ºå°‘ä¸Šä¸‹æ–‡

æ•°æ®è¡¨æ˜ï¼Œå°† RAG æ£€ç´¢ç»“æœå‘é€ç»™å¤§æ¨¡å‹å‰ï¼Œå¯¹å…¶é‡æ’åºä¼šæ˜¾è‘—æé«˜ RAG æ€§èƒ½ï¼š

```
import os
from llama_index.postprocessor.cohere_rerank import CohereRerank

api_key = os.environ["COHERE_API_KEY"]
cohere_rerank = CohereRerank(api_key=api_key, top_n=2) # return top 2 nodes from reranker

query_engine = index.as_query_engine(
    similarity_top_k=10, # we can set a high top_k here to ensure maximum relevant retrieval
    node_postprocessors=[cohere_rerank], # pass the reranker to node_postprocessors
)

response = query_engine.query(
    "What did Elon Musk do?",
)
```

è¿™æ®µ LlamaIndex ä»£ç æ˜¾ç¤ºäº†äºŒè€…åŒºåˆ«ï¼Œä¸ä½¿ç”¨é‡æ’å™¨å¯¼è‡´ç»“æœä¸å‡†ç¡®ï¼›

ä½†æ˜¯ï¼Œé€šè¿‡é‡æ’å¯èƒ½å¯¼è‡´ä¸Šä¸‹æ–‡çš„ç¼ºå¤±ï¼Œæ‰€ä»¥éœ€è¦æ›´å¥½çš„æ£€ç´¢ç­–ç•¥ï¼š

*   å¯¹æ¯ä¸ªç´¢å¼•åŸºæœ¬æ£€ç´¢
*   é«˜çº§æ£€ç´¢å’Œæœç´¢
*   è‡ªåŠ¨æ£€ç´¢
*   çŸ¥è¯†å›¾è°±æ£€ç´¢å™¨
*   ç»„åˆ/å±‚æ¬¡åŒ–æ£€ç´¢å™¨

![Image 29](https://developer.qcloudimg.com/http-save/yehe-7738744/deeb873fb13bd13ebc26f341b9789691.webp)

å¦‚æœæ£€ç´¢æ•ˆæœä»ä¸å¼ºï¼Œå¯ä»¥è€ƒè™‘åŸºäºæ•°æ®å¾®è°ƒæ¨¡å‹ï¼ŒåŠ å…¥åµŒå…¥æ¨¡å‹ï¼Œé€šè¿‡è‡ªå®šä¹‰åµŒå…¥æ¨¡å‹å¸®åŠ©åŸå§‹æ•°æ®æ›´å‡†ç¡®çš„è½¬ä¸ºå‘é‡æ•°æ®åº“ã€‚

#### 4. æœªæå–ä¸Šä¸‹æ–‡

å½“ä¿¡æ¯è¿‡è½½æ—¶ï¼Œè¿˜å¯èƒ½å‡ºç°ï¼šæœªæå–ä¸Šä¸‹æ–‡ï¼Œå…³é”®ä¿¡æ¯é—æ¼ï¼Œå½±å“å›ç­”è´¨é‡ã€‚

æˆ‘ä»¬å¯ä»¥å°è¯•å°†æç¤ºå‹ç¼©ï¼Œåœ¨æ£€ç´¢æ­¥éª¤ä¹‹åï¼ŒæŠŠæ•°æ®å–‚ç»™ LLM ä¹‹å‰é€šè¿‡ LongLLMLingua å‹ç¼©ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥ä½¿æˆæœ¬æ›´ä½ã€æ€§èƒ½æ›´å¥½ã€‚

```
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.response_synthesizers import CompactAndRefine
from llama_index.postprocessor.longllmlingua import LongLLMLinguaPostprocessor
from llama_index.core import QueryBundle

node_postprocessor = LongLLMLinguaPostprocessor(
    instruction_str="Given the context, please answer the final question",
    target_token=300,
    rank_method="longllmlingua",
    additional_compress_kwargs={
        "condition_compare": True,
        "condition_in_question": "after",
        "context_budget": "+100",
        "reorder_context": "sort",  # enable document reorder
    },
)

retrieved_nodes = retriever.retrieve(query_str)
synthesizer = CompactAndRefine()

# outline steps in RetrieverQueryEngine for clarity:
# postprocess (compress), synthesize
new_retrieved_nodes = node_postprocessor.postprocess_nodes(
    retrieved_nodes, query_bundle=QueryBundle(query_str=query_str)
)

print("nn".join([n.get_content() for n in new_retrieved_nodes]))

response = synthesizer.synthesize(query_str, new_retrieved_nodes)
```

å°±åƒäººå†™æ–‡ç« ä¸€æ ·ï¼Œè™å¤´å‡¤å°¾çŒªè‚šï¼Œé‡è¦çš„ä¸œè¥¿æ”¾åœ¨é¦–ä½ï¼Œå¯¹äºå¤§æ¨¡å‹æç¤ºè¯­ä¹Ÿæ˜¯ä¸€æ ·ï¼š

![Image 30](https://developer.qcloudimg.com/http-save/yehe-7738744/3847f6c55509bacae316c4820c1f9e8c.webp)

ç ”ç©¶è¡¨æ˜ï¼šè‡ªæ³¨æ„åŠ›æœºåˆ¶å¯¹å¤´éƒ¨ä¿¡æ¯å…³æ³¨æ›´å¤šã€‚

#### 5. è¾“å‡ºæ ¼å¼é”™è¯¯

RAG é€šé“éœ€è¦è¾“å‡º JSON ç­”æ¡ˆï¼Œæˆ‘ä»¬ä¹Ÿè¦ä¿è¯è¾“å‡ºæ ¼å¼:

*   ä½¿ç”¨OpenAIå‡½æ•°è°ƒç”¨+ JSONæ¨¡å¼
*   ä½¿ç”¨ä»¤ç‰Œçº§æç¤ºï¼ˆLMQLï¼ŒGuidanceï¼‰
*   LlamaIndexæ”¯æŒä¸å…¶ä»–æ¡†æ¶æä¾›çš„è¾“å‡ºè§£ææ¨¡å—é›†æˆï¼Œä¾‹å¦‚Guardrailså’ŒLangChainã€‚

å‚è§ä»¥ä¸‹ LangChain è¾“å‡ºè§£ææ¨¡å—çš„ç¤ºä¾‹ä»£ç ï¼š

```
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
from llama_index.core.output_parsers import LangchainOutputParser
from llama_index.llms.openai import OpenAI
from langchain.output_parsers import StructuredOutputParser, ResponseSchema

# load documents, build index
documents = SimpleDirectoryReader("../paul_graham_essay/data").load_data()
index = VectorStoreIndex.from_documents(documents)

# define output schema
response_schemas = [
    ResponseSchema(
        name="Education",
        description="Describes the author's educational experience/background.",
    ),
    ResponseSchema(
        name="Work",
        description="Describes the author's work experience/background.",
    ),
]

# define output parser
lc_output_parser = StructuredOutputParser.from_response_schemas(
    response_schemas
)
output_parser = LangchainOutputParser(lc_output_parser)

# Attach output parser to LLM
llm = OpenAI(output_parser=output_parser)

# obtain a structured response
query_engine = index.as_query_engine(llm=llm)
response = query_engine.query(
    "What are a few things the author did growing up?",
)
print(str(response))
```

Pydantic åº“å¯æä¾›å¤§å‹è¯­è¨€æ¨¡å‹ç»“æ„åŒ–ï¼š

```
from pydantic import BaseModel
from typing import List

from llama_index.program.openai import OpenAIPydanticProgram

# Define output schema (without docstring)
class Song(BaseModel):
    title: str
    length_seconds: int


class Album(BaseModel):
    name: str
    artist: str
    songs: List[Song]

# Define openai pydantic program
prompt_template_str = """
Generate an example album, with an artist and a list of songs. 
Using the movie {movie_name} as inspiration.
"""
program = OpenAIPydanticProgram.from_defaults(
    output_cls=Album, prompt_template_str=prompt_template_str, verbose=True
)

# Run program to get structured output
output = program(
    movie_name="The Shining", description="Data model for an album."
)
```

#### 6. è¾“å‡ºä¸æ¸…æ™°

è¿˜æœ‰é—®é¢˜æ˜¯ï¼šè¾“å‡ºçš„å†…å®¹ä¸æ¸…æ™°ï¼Œå¯¼è‡´å¤§æ¨¡å‹å›ç­”ä¹Ÿä¸å°½å¦‚äººæ„ï¼Œéœ€è¦å¤šè½®å¯¹è¯ã€æ£€ç´¢æ‰èƒ½å¾—åˆ°ç­”æ¡ˆï¼›

è§£å†³æ–¹æ¡ˆï¼ŒåŒæ ·å¯ä»¥ä¼˜åŒ–æ£€ç´¢ç­–ç•¥ï¼š

*   æ£€ç´¢ä»å°åˆ°å¤§
*   ä½¿ç”¨å¥å­çª—å£æ£€ç´¢
*   é€’å½’æ£€ç´¢

#### 7. è¾“å‡ºä¸å®Œæ•´

æœ‰æ—¶å€™é—®æ³•ä¸ä¸€æ ·ï¼Œç»“æœå°±ä¸ä¸€æ ·ï¼šæ¯”å¦‚é—®ï¼š

*   â€œæ–‡æ¡£Aã€Bã€Cçš„ä¸»è¦è§‚ç‚¹â€ï¼›
*   â€œæ–‡æ¡£Açš„è§‚ç‚¹ã€æ–‡æ¡£Bçš„è§‚ç‚¹ã€æ–‡æ¡£Cçš„è§‚ç‚¹ã€â€

è¿™ä¸¤ä¸ªé—®é¢˜ç»“æœæ˜¯ä¸ä¸€æ ·çš„ï¼Œåè€…ä¼šæ›´åŠ å…¨é¢ï¼›æ”¹è¿› RAG æ¨ç†èƒ½åŠ›çš„ä¸€ä¸ªå¥½æ–¹æ³•æ˜¯æ·»åŠ ä¸€ä¸ªæŸ¥è¯¢ç†è§£å±‚ â€”â€” åœ¨å®é™…æŸ¥è¯¢å‘é‡å­˜å‚¨ä¹‹å‰æ·»åŠ æŸ¥è¯¢è½¬æ¢ã€‚

æœ‰ 4 ç§ä¸åŒçš„æŸ¥è¯¢è½¬æ¢ï¼š

*   è·¯ç”±ï¼šä¿ç•™åˆå§‹æŸ¥è¯¢ï¼ŒåŒæ—¶ç²¾ç¡®å®šä½å®ƒæ‰€æ¶‰åŠçš„é€‚å½“å·¥å…·å­é›†ã€‚ç„¶åï¼ŒæŒ‡å®šè¿™äº›å·¥å…·ä¸ºåˆé€‚çš„é€‰é¡¹ã€‚
*   æŸ¥è¯¢é‡å†™ï¼šä¿ç•™é€‰å®šçš„å·¥å…·ï¼Œä»¥å¤šç§æ–¹å¼é‡æ–°æ„å»ºæŸ¥è¯¢ï¼Œä»¥ä¾¿åœ¨åŒä¸€ç»„å·¥å…·ä¸Šåº”ç”¨ã€‚
*   å­é—®é¢˜ï¼šå°†æŸ¥è¯¢åˆ†è§£ä¸ºå‡ ä¸ªè¾ƒå°çš„é—®é¢˜ï¼Œæ¯ä¸ªé—®é¢˜é’ˆå¯¹ç”±å…¶å…ƒæ•°æ®ç¡®å®šçš„ä¸åŒå·¥å…·ã€‚
*   ReActä»£ç†å·¥å…·é€‰æ‹©ï¼šåŸºäºåŸå§‹æŸ¥è¯¢ï¼Œç¡®å®šä½¿ç”¨å“ªä¸ªå·¥å…·ï¼Œå¹¶åˆ¶å®šåœ¨è¯¥å·¥å…·ä¸Šè¿è¡Œçš„å…·ä½“æŸ¥è¯¢ã€‚

![Image 31](https://developer.qcloudimg.com/http-save/yehe-7738744/cf7bafff3920d2b7dc61b37d9fac8909.webp)

#### 8. æ— æ³•æ‰©å±•åˆ°æ›´å¤§çš„æ•°æ®é‡

å½“å¤„ç†å¾ˆå¤§çš„ä¸“ä¸šæ•°æ®åº“ã€ç§äººæ•°æ®åº“æ—¶ï¼ŒRAG é€šé“ä¼šå‡ºç°å¤„ç†å¾ˆæ…¢ç”šè‡³æ— æ³•å¤„ç†çš„æƒ…å†µï¼›

å¯ä»¥é‡‡å–å¹¶è¡ŒåŒ–æå–ç®¡é“ï¼Œæ¯”å¦‚ï¼š

â— å¹¶è¡ŒåŒ–æ–‡æ¡£å¤„ç†

â— HuggingFace TEI

â— RabbitMQ æ¶ˆæ¯é˜Ÿåˆ—

â— AWS EKS é›†ç¾¤

![Image 32](https://developer.qcloudimg.com/http-save/yehe-7738744/c5ccb6bdc91474292119a76d903ccd43.webp)

å®é™…ä¸Šï¼ŒLlamaIndex å·²ç»æä¾›å¹¶è¡Œå¤„ç†åŠŸèƒ½ï¼Œæ–‡æ¡£å¤„ç†é€Ÿåº¦æé«˜ 15 å€ï¼š

```
# load data
documents = SimpleDirectoryReader(input_dir="./data/source_files").load_data()

# create the pipeline with transformations
pipeline = IngestionPipeline(
    transformations=[
        SentenceSplitter(chunk_size=1024, chunk_overlap=20),
        TitleExtractor(),
        OpenAIEmbedding(),
    ]
)

# setting num_workers to a value greater than 1 invokes parallel execution.
nodes = pipeline.run(documents=documents, num_workers=4)
```

#### 9. é€Ÿç‡é™åˆ¶

å¦‚æœå¤§æ¨¡å‹çš„ API å…è®¸é…ç½®å¤šä¸ªå¯†é’¥ã€ä¸€ä¸ªåº”ç”¨è½®ç•ªè°ƒç”¨ï¼Œå¯ä»¥é‡‡ç”¨åˆ†å¸ƒå¼ç³»ç»Ÿï¼Œå°†è¯·æ±‚åˆ†æ•£åˆ°å¤šä¸ª RAG é€šé“ï¼Œå³ä½¿é€šé“æœ‰é€Ÿç‡é™åˆ¶ï¼Œä¹Ÿèƒ½é€šè¿‡è´Ÿè½½å‡è¡¡ã€åŠ¨æ€åˆ†é…è¯·æ±‚çš„æ–¹å¼æ¥è§£å†³è¿™ä¸ªé€Ÿç‡é™åˆ¶é—®é¢˜ã€‚

### æ€»ç»“

æœ¬ç¯‡æä¾›äº†å¼€å‘ RAG é€šé“ 9 ä¸ªç—›ç‚¹ï¼Œå¹¶é’ˆå¯¹æ¯ä¸ªç—›ç‚¹éƒ½ç»™äº†ç›¸åº”çš„è§£å†³æ€è·¯ã€‚

RAG æ˜¯éå¸¸é‡è¦çš„ä¸“ç”¨æ£€ç´¢+é€šç”¨å¤§æ¨¡å‹çš„æŠ€æœ¯æ‰‹æ®µï¼Œåœ¨èµ‹èƒ½æ¨¡å‹ã€æ»¡è¶³ç‰¹å®šåŒ–åœºæ™¯ä¸­éå¸¸é‡è¦ï¼

åç»­æœ‰æœºä¼šï¼Œæœ¬ç“œè¿˜ä¼šä»‹ç»ç›¸å…³å†…å®¹ï¼Œæ•¬è¯·æœŸå¾…ã€‚

**å‚è€ƒï¼š**

[medium.com/aiguys/solvâ€¦](https://cloud.tencent.com/developer/tools/blog-entry?target=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3Dhttps%253A%252F%252Fmedium.com%252Faiguys%252Fsolving-production-issues-in-modern-rag-systems-b7c31802167c&objectId=2404634&objectType=1&isNewArticle=undefined)

[discussion.coggle.club/t/topic/30](https://cloud.tencent.com/developer/tools/blog-entry?target=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3Dhttp%253A%252F%252Fdiscussion.coggle.club%252Ft%252Ftopic%252F30&objectId=2404634&objectType=1&isNewArticle=undefined)

[www.zhihu.com/question/63â€¦](https://cloud.tencent.com/developer/tools/blog-entry?target=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3Dhttps%253A%252F%252Fwww.zhihu.com%252Fquestion%252F637421964%252Fanswer%252F3344775790&objectId=2404634&objectType=1&isNewArticle=undefined)

æœ¬æ–‡å‚ä¸Â [è…¾è®¯äº‘è‡ªåª’ä½“åŒæ­¥æ›å…‰è®¡åˆ’](https://cloud.tencent.com/developer/support-plan)ï¼Œåˆ†äº«è‡ªä½œè€…ä¸ªäººç«™ç‚¹/åšå®¢ã€‚

åŸå§‹å‘è¡¨ï¼š2024-04-04ï¼Œ

å¦‚æœ‰ä¾µæƒè¯·è”ç³» [cloudcommunity@tencent.com](mailto:cloudcommunity@tencent.com) åˆ é™¤

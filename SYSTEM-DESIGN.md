## Database Schema
### Design Considerations
- Metadata Strategy: Capture detailed metadata to facilitate search, filtering, and idea generation. Use fields like weight, area, topic, branch, and persons to categorize and relate articles.
- Data Fusion: Use the Relations table to store static relationships between articles. This can be used to identify connections and patterns.
- Dynamic Idea Generation: The Ideas table will store insights generated by LLMs, allowing the system to suggest new connections and ideas based on existing articles.
### Tables
    Articles
        id: Unique identifier
        title: Title of the article
        url: URL of the article
        source: Source of the article
        publication_date: Date of publication
        content: Full content or summary of the article
        weight: Interest level (could be multidimensional)
        area: Primary domain level
        topic: Secondary domain level
        branch: Tertiary domain level
        persons: People mentioned in the article
        key_points: Key points or topics discussed
        problem: Problem addressed and methods used (optional)
    Relations
        id: Unique identifier
        article_id_1: Reference to an article
        article_id_2: Reference to another article
        relation_type: Type of relation (e.g., same topic, same author)
    Ideas
        id: Unique identifier
        article_ids: List of related articles
        generated_idea: Idea generated by LLM
        timestamp: When the idea was generated
        relevance_score: How relevant the idea is

## Collection Mechanism
1. Positive Collecting(from browser or notebook)
    Notion 
    Chrome 
2. Web Scraping
    JINA Scraping Tool: https://jina.ai/reader/
3. PDF Collection
    [readpaper.com](https://readpaper.com/home/library)

## Integrate LLM/VLM
### Design Considerations
1. Local LLM and Remote API Support
Local LLMs: Use open-source models like GPT-Neo or LLaMA for on-device processing, which offers privacy and control over data.
Remote APIs: Integrate with services like OpenAI's GPT, Google's PaLM, or other cloud-based LLMs for more powerful processing capabilities.
Hybrid Approach: Implement a system that can switch between local and remote processing based on the task, data sensitivity, or computational resources.
2. Multi-Modal Input Support
Text Input: Process and analyze text articles using LLMs for summarization, key point extraction, and idea generation.
Vision Input: Use VLMs to analyze images or figures in articles, extracting relevant information or generating descriptions.
Audio Input: Incorporate audio processing capabilities to transcribe and analyze spoken content from podcasts or interviews.
3. Framework/RAG/Agent Support
Frameworks: Utilize frameworks like LangChain or Haystack for building applications that leverage LLMs for tasks like question answering, summarization, and document retrieval.
RAG (Retrieval-Augmented Generation): Implement RAG techniques to enhance LLM responses by retrieving relevant information from your database before generating outputs.
Agent Support: Design agents that can autonomously interact with the system, executing tasks like finding related articles, generating ideas, or summarizing content.
4. LLM/LVM tasks Design
    1. 总结 For every new article/media/information, we need LLM to summarize them, substract key-points/ideas/questions/topics/lables.
    2. 关联 For every new article/media/information, We need LLM to find relations by go through history in database to find related articles base on silimar key-points/ideas/questions/topics/lables. This is the first level of discovery. But, considering the amount of data, we need to think a way to reduce the number of relations.
    3. 发现 We need LLM to generate ideas during a time period, this is not for every new article, but for a period of time. Because relations are a large database, but only large is not enough, too many relations could even be redundant. We will design a shedule strategy for this. Ideas are information further extracted based on relations, they are the second level of discovery.

## Design User Interface
- User can search text in Title, Summary, Key Points, Tags. We will implement this in a db equal search way first for simple, in the future, we will upgrade the way in a vector comparing way to allow NLP silimar search.
